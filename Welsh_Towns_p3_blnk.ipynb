{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Capstone Project - The Battle of Neighbourhoods: Welsh Towns Review</center>\n",
    "## <center>Part 3 - Methodology</center>\n",
    "### Applied Data Science Capstone by IBM\n",
    "### Part of our IBM Data Science Professional Certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [The Problem](#section1)\n",
    "* [Data Analysis](#section2)\n",
    "    * [A. Secondary Schools Data](#section3)\n",
    "    * [B. Average Property Prices per County in Wales](#section4)\n",
    "    * [C. Correlation between the school rating and average property price](#section5)\n",
    "    * [D. Clustering of the towns](section6)\n",
    "* [Presentation of Results](#section7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem <a name=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple with young children is looking for a safe and quiet place to live. For their children they want a good state school and for the family a small, but vibrant town. They would like either to settle in that town or very close. They are flexible in regards to the location because they both work from home with only occasional business travels to a city. But where to start? Where are the good schools and which towns could be nice to live in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis<a name=\"section2\"></a>\n",
    "\n",
    "Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data analysis\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "\n",
    "# for charting:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# for presentation on a map: \n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Secondary Schools Data<a name=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous workbooks we downloaded and cleaned the data: <br>\n",
    "1. Download list of schools in Wales including their 2019 rating:<br>\n",
    "https://gov.wales/sites/default/files/publications/2020-02/national-school-categorisation-system-support-categories-2019-v2.xlsx \n",
    "It is a large file with complex headings and multiple tabs. The most efficient way of loading the date is by pre-processing it in Ms Excel. Primary and special schools have been removed as well as the empty cells. Finally the headings were simplified.\n",
    "2.  To present the schools on a map, their addresses are obtained from the Welsh Governent’s website: <br>\n",
    "https://gov.wales/sites/default/files/publications/2021-02/address-list-schools-wales.ods. <br>\n",
    "The two tables were joined and the size reduced to few most important columns only: `['School_code', 'School_name', 'Local_authority', 'Rating', 'Postcode']`.\n",
    "3. The data set was geolocated using 'Geocoder' and results saved as: `schools_geo.csv`\n",
    "\n",
    "Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = pd.read_csv('schools_geo.csv')\n",
    "schools.info()\n",
    "schools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the yellow and green schols to display them in different colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with yellow rated schools 'Green/Gwyrdd': \n",
    "schools_g = schools[schools.Rating == 'Green/Gwyrdd']\n",
    "schools_g.info()\n",
    "schools_g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with yellow rated schools 'Yellow/Melyn': \n",
    "schools_y = schools[schools.Rating == 'Yellow/Melyn']\n",
    "schools_y.info()\n",
    "schools_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Average Property Prices per County in Wales<a name=\"section4\"></a>\n",
    "\n",
    "Load data prepared in the previous notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average property prices per county downloaded from uk.gov website:\n",
    "counties = pd.read_csv('Prices_Wales.csv') # two of the county names required a slight edit to match the other schools table.\n",
    "\n",
    "counties.info()\n",
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data-set with all schools rated, drop columns that are not required,\n",
    "df1 = pd.read_csv('schools_rated.csv')\n",
    "df1 = df1.drop(['Consortium', 'LA Code', 'Sector', 'Governance - see notes', 'WM Code', 'Welsh Medium Type - see notes', 'School Type', 'Religious Character', 'Address 1', 'Address 2', \n",
    "                'Address 3', 'Address 4', 'Postcode', 'Phone Number', 'Pupils - see notes'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot counting the number of schools per 'Local_authority':\n",
    "\n",
    "df2 = pd.pivot_table(df1, values = 'School_code', index = ['Local_authority'], aggfunc = 'count')\n",
    "df2.rename(columns = {'School_code':'No_Schools'}, inplace = True)\n",
    "\n",
    "# Create a pivot counting the number of schools with each rating per 'Local_authority':\n",
    "df3 = pd.pivot_table(df1, values = 'School_code', index = ['Local_authority'], columns = 'Rating', aggfunc = 'count')\n",
    "df3.fillna(0, inplace = True)\n",
    "\n",
    "# Merge the two data frames:\n",
    "df4 = pd.merge(df2, df3, on = 'Local_authority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with proportion of schools in each category:\n",
    "df4['Green%'] = df4['Green/Gwyrdd'] / df4['No_Schools']\n",
    "df4['Yellow%'] = df4['Yellow/Melyn'] / df4['No_Schools']\n",
    "df4['Amber%'] = df4['Amber/Oren'] / df4['No_Schools']\n",
    "df4['Red%'] = df4['Red/Coch'] / df4['No_Schools']\n",
    "\n",
    "# Reset index\n",
    "#df4.reset_index(drop = False)\n",
    "df4.reset_index(inplace = True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Correlation between the school rating and average property price<a name=\"section5\"></a>\n",
    "Now we can to see whether there is correlation between the school rating and average property prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Welsh county name from 'Local_authority' to enable data match\n",
    "df4['Local_authority'].replace(to_replace=r' / .*', value='', regex=True, inplace=True)\n",
    "\n",
    "# Rename 'County' column to enable matching\n",
    "counties.rename(columns = {'County':'Local_authority'}, inplace = True)\n",
    "\n",
    "# add average property price to the df4:\n",
    "df5 = pd.merge(df4, counties, on = 'Local_authority')\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.drop(['No_Schools', 'Amber/Oren', 'Green/Gwyrdd', 'Red/Coch', 'Yellow/Melyn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a Seaborn heatmap\n",
    "fig, ax = plt.subplots(figsize=(20,10)) # size of a single point/field in inches\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "sns.heatmap(df5.corr(), annot=True, fmt=\".0%\", linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To picture the results clearly two new columns were added to the data frame. One column converted the price values into a 0 – 1 range showing each county’s average property price against the minimum and maximum difference, where 1 is the cheapest and 0 is the most expensive county. The same was done with the proportion of green schools within each county’s school number, but here 1 means the highest proportion of schools ranked ‘green’ and ‘0’ the lowest.\n",
    "In this way, xx shows the best value for money in terms of excellent schools when the county has plotted the closet to the top right: both values going towards ‘1’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['Price_Index'] = (max(df5['Ave_price_2021']) - df5['Ave_price_2021']) / (max(df5['Ave_price_2021'])-min(df5['Ave_price_2021']))\n",
    "df5['School_Index'] = (df5['Green%']-min(df5['Green%'])) / (max(df5['Green%'])-min(df5['Green%']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.drop(['Yellow%', 'Amber%', 'Red%'], axis=1)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df6, x = 'Price_Index', y = 'School_Index', size = 'School_Index', legend = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data:\n",
    "x = df6['Price_Index']\n",
    "y = df6['School_Index']\n",
    "types = df6['Local_authority'].values\n",
    "\n",
    "# Marker size (s) and colour (c):\n",
    "price = df6['Price_Index'] * 500\n",
    "school = df6['School_Index'] * 500\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "ax.scatter(x, y, c=price, s=school, alpha=1)\n",
    "\n",
    "ax.set_xlabel(r'Price Index', fontsize=15)\n",
    "ax.set_ylabel(r'School Index', fontsize=15)\n",
    "ax.set_title('Ranking of Counties: property price and school ranking')\n",
    "\n",
    "# Label data points:\n",
    "for i, txt in enumerate(types):\n",
    "    ax.annotate(txt, (x[i], y[i]), xytext=(10,10), textcoords='offset points')\n",
    "    plt.scatter(x, y, marker='None', color='black')\n",
    "\n",
    "#ax.legend()\n",
    "ax.grid(True) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Clustering of the towns <a name=\"section6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already downloaded the venue data for all 132 towns / localities in Wales using Four Square API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv('venues.csv')\n",
    "df7.rename(columns = {'Neighbourhood':'Town', 'Neighbourhood Latitude':'T_Lati', 'Neighbourhood Longitude':'T_Long'}, inplace = True)\n",
    "df7.info()\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many venues per town the search returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df7.groupby('Town').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the unique venue categories that Four Square returned and their number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Venue Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"there are \", df7['Venue Category'].nunique(), \" unique venue types in the selected towns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the dataframe to have the unique venues as colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# venues as columns:\n",
    "wales_onehot = pd.get_dummies(df7[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add town column back to dataframe\n",
    "wales_onehot['Town'] = df7['Town'] \n",
    "\n",
    "# move neighbourhood column to the first column\n",
    "fixed_columns = [wales_onehot.columns[-1]] + list(wales_onehot.columns[:-1])\n",
    "wales_onehot = wales_onehot[fixed_columns]\n",
    "\n",
    "wales_onehot.info()\n",
    "wales_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group rows by town and by taking the mean of the frequency of occurrence of each category normalise the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wales_grouped = wales_onehot.groupby('Town').mean().reset_index()\n",
    "print('Size of the new table: ', wales_grouped.shape)\n",
    "wales_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wales_grouped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print each neighbourhood along with the top 10 most common venues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 3\n",
    "\n",
    "for town in wales_grouped['Town']:\n",
    "    print(\"----\"+town+\"----\")\n",
    "    temp = wales_grouped[wales_grouped['Town'] == town].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 3})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put the data in a dataframe we can first sort the venues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sorting function:\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new dataframe and display the top 10 venues for each neighbourhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Town']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "towns_venues_sorted = pd.DataFrame(columns=columns)\n",
    "towns_venues_sorted['Town'] = wales_grouped['Town']\n",
    "\n",
    "for ind in np.arange(wales_grouped.shape[0]):\n",
    "    towns_venues_sorted.iloc[ind, 1:] = return_most_common_venues(wales_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "print('Size of the new table: ', towns_venues_sorted.shape)\n",
    "towns_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the table as csv to append in the report:\n",
    "# towns_venues_sorted.to_csv(r'towns_venues_sorted.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add normalised town population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv('towns_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df8.drop(['Latitude', 'Longitude'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8['Pop_Index'] = (df8['Population']-min(df8['Population'])) / (max(df8['Population'])-min(df8['Population']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df8.drop(['Population'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.merge(wales_grouped, df8, on = 'Town', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster the neigbourhoods using K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 6\n",
    "\n",
    "wales_grouped_clustering = df9.drop('Town', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(wales_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe that includes the cluster as well as the top 3 venues for each neighbourhood\n",
    "\n",
    "# add clustering labels\n",
    "towns_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "wales_merged = pd.read_csv('towns_geo.csv')\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighbourhood\n",
    "wales_merged = wales_merged.join(towns_venues_sorted.set_index('Town'), on='Town')\n",
    "\n",
    "wales_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wales_merged.sort_values(by = ['Cluster Labels'], inplace = True)\n",
    "wales_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation of Results <a name=\"section7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the towns data:\n",
    "towns = pd.read_csv('towns_geo.csv')\n",
    "# Create a centre point coordinations for Wales using the mean lat-lon from the dataframe:\n",
    "lat = towns['Latitude'].mean()\n",
    "lon = towns['Longitude'].mean()\n",
    "print('Wales mean coordinates /lat - lon/: ',lat,' , ',lon)\n",
    "# Load the county boundaries downloaded from the gov.uk website:\n",
    "geo_data = r'Counties_and_Unitary_Authorities_(December_2016)_Boundaries.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blank Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a blank map of Wales:\n",
    "map_w = folium.Map(location=[lat, lon], zoom_start=7, tiles='cartodbpositron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the counties Choropleth coloured by the average price:\n",
    "\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data,\n",
    "    data=counties, # my dataset with prices\n",
    "    columns=['Local_authority', 'Ave_price_2021'], # 'County' is here for matching the geojson 'ctyua16nm', 'Ave_price_2021' is the column that changes the color of zipcode areas\n",
    "    key_on='feature.properties.ctyua16nm', # this path contains counties in str type and should match with our 'County column\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=0.4,\n",
    "    line_color= 'None',\n",
    "    legend_name='Average Property Price, Wales 2021',\n",
    "    nan_fill_color = 'None'\n",
    ").add_to(map_w)\n",
    "\n",
    "# add labels indicating the name of the county\n",
    "style_function = \"font-size: 10px; font-weight: normal\"\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['ctyua16nm'], style=style_function, labels=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add schools to map\n",
    "# Green:\n",
    "for lat_s, lng_s, school, rating in zip(schools_g['Latitude'], schools_g['Longitude'], schools_g['School_name'], schools_g['Rating']):\n",
    "    label = '{}'.format(str(school) + ' support category: ' + str(rating))\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat_s, lng_s],\n",
    "        radius=4,\n",
    "        stroke=True,\n",
    "        color='black',\n",
    "        weight=2,\n",
    "        fill=True,\n",
    "        fill_color='green',\n",
    "        fill_opacity=1,\n",
    "        popup=label,\n",
    "        parse_html=False).add_to(map_w)  \n",
    "    \n",
    "# Yellow:\n",
    "for lat_s, lng_s, school, rating in zip(schools_y['Latitude'], schools_y['Longitude'], schools_y['School_name'], schools_y['Rating']):\n",
    "    label = '{}'.format(str(school) + ' support category: ' + str(rating))\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat_s, lng_s],\n",
    "        radius=4,\n",
    "        stroke=True,\n",
    "        color='black',\n",
    "        weight=2,\n",
    "        fill=True,\n",
    "        fill_color='yellow',\n",
    "        fill_opacity=1,\n",
    "        popup=label,\n",
    "        parse_html=False).add_to(map_w)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towns - Clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to map\n",
    "markers_colors = []\n",
    "for lat, lng, poi, cluster in zip(wales_merged['Latitude'], wales_merged['Longitude'], wales_merged['Town'], wales_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        stroke=False,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_w)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tile layers to the map:\n",
    "tiles = ['stamenwatercolor', 'cartodbpositron', 'openstreetmap', 'stamenterrain']\n",
    "for tile in tiles:\n",
    "    folium.TileLayer(tile).add_to(map_w)\n",
    "\n",
    "# create a layer control:\n",
    "folium.LayerControl().add_to(map_w)\n",
    "\n",
    "# plot the map:\n",
    "map_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above interactive map concludes the project as browsable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
